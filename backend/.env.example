
# Environment variables

# # For Hugging Face (default):
# HUGGINGFACE_API_KEY=your_huggingface_api_key_here
# MODEL_NAME=mistralai/Mistral-7B-Instruct
# API_BASE_URL=https://api-inference.huggingface.co/models/
# Model used for Hugging Face: see MODEL_NAME (e.g. mistralai/Mistral-7B-Instruct, google/gemma-2b, etc.)
# ---- Cohere API Configuration (ACTIVE) ----
COHERE_API_KEY=hZN8CmqOEb8FyWzo9RVwJDUMe0ww55JSv9c5HkQK
#
PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# # For Google Gemini (optional, takes priority if set):
# GEMINI_API_KEY=AIzaSyAAUokb_45IHj1PQgDes0uXhDmLYpj0sFA
# GEMINI_API_URL=https://generativelanguage.googleapis.com/v1/models/gemini-1.5-pro:generateContent
# # Model used for Gemini: gemini-pro (default endpoint)

CORS_ORIGINS=http://localhost:3000,https://your-vercel-domain.vercel.app






